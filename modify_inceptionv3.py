
# coding: utf-8

# In[1]:


import torch
import torchvision
from torch import nn
from torch.autograd import Variable



# In[9]:


class InceptionAux(nn.Module):

    def __init__(self, in_channels, num_classes):
        super(InceptionAux, self).__init__()
        self.conv0 = BasicConv2d(in_channels, 128, kernel_size=1)
        self.conv1 = BasicConv2d(128, 768, kernel_size=5)
        self.conv1.stddev = 0.01
        self.fc = nn.Linear(768, num_classes)
        self.fc.stddev = 0.001

    def forward(self, x):
        # 17 x 17 x 768
        x = F.avg_pool2d(x, kernel_size=5, stride=3)
        # 5 x 5 x 768
        x = self.conv0(x)
        # 5 x 5 x 128
        x = self.conv1(x)
        # 1 x 1 x 768
        x = x.view(x.size(0), -1)
        # 768
        x = self.fc(x)
        # 1000
        return x

    

class BasicConv2d(nn.Module):

    def __init__(self, in_channels, out_channels, **kwargs):
        super(BasicConv2d, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)
        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)

    def forward(self, x):
        x = self.conv(x)
        x = self.bn(x)
        return F.relu(x, inplace=True)
    


# In[3]:


# inception = torchvision.models.inception_v3(pretrained=False)


# In[10]:


# inception.AuxLogits = InceptionAux(in_channels=768, num_classes=43)


# In[11]:


def get_pretrained_inception(num_classes, pretrained=True):
    inception = torchvision.models.inception_v3(pretrained=pretrained)
    
    fc_in_features = inception.fc.in_features
    inception.fc = nn.Linear(in_features=fc_in_features, out_features=num_classes)
    inception.AuxLogits = InceptionAux(in_channels=768, num_classes=num_classes)
    
    return inception
    

